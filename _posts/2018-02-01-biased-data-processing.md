---
layout: post
title: 数据不均衡的处理方法
categories: [机器学习]
description: 数据不均衡的处理方法
keywords: 机器学习, 分类, 数据不均衡, 调研
---


<h2 align = "center"> 数据不均衡的处理方法 </h2>

<br/>


## 1. 定义

训练样本在各类别之间的分布不相等，称之为数据不均衡。但是，一般来说，只有数据的不均衡达到一定程度，正、负样本的数量比例达到10:1,100:1甚至1000:1，才认为是不均衡的，或者说才考虑不均衡的影响。

正常情况下，数据量大的类别，分类准确率会很高，数据量小的类别，分类准确率会极低。而将正负样本分类错，影响是很大的，例如在进行癌症诊断时，患病的样本相比正常的样本是极其稀少的，样本的不均衡会导致分类器会将较多患病的诊断为正常的，这样会造成极大的影响

处理数据不均衡问题的处理，目前主要从三个方面进行考虑：

*	首先是从**样本层面**进行考虑，设计合理的采样方法，使得训练数据均衡；
*	其次是从**模型和算法**的角度考虑，设计或改进方法，减小不均衡的影响；
*	最后是从**分类的评价标准**上考虑，设计合理的评价指标，评估模型分类非均衡数据的效果。


## 2.样本层面--采样方法

### 2.1 随机欠采样和过采样
采样算法通过某一种策略改变样本的类别分布，以达到将不平衡分布的样本转化为相对平衡分布的样本的目的。而随机采样是采样算法中最简单也最直观易懂的一种方法。随机采样主要分为两种类型。分别为随机欠采样和随机过采样两种。

* **随机欠采样**：从样本多的类别中随机选出一部分数据，与样本少的类别，组成新的数据集；
* **随机过采样**：通过有放回的方式，样本少的类别中随机选出样本，样本的数量多于原有数量，与样本多的数据形成新的数据集。

随机欠采样会导致信息丢失，随机过采样会导致过拟合。

### 2.2 依据信息的欠采样(Informed Undersampling)

Informed Undersampling主要有两种方法：EasyEnsemble和BalanceCascade算法，这两种算法的目的是克服随机欠采样过程中的信息丢失。

*	EasyEnsemble：将数据较多的类别，划分成多个子数据集，分别与数据量少的类别组成新的数据集，训练多个模型。
*	BalanceCascade：建立了一个有监督的继承学习方法，来系统地选择多数类中的哪个样本被采样。对于从多数类中的某一次采样，与少数类组合训练一个模型，然后使用模型来对本次多数类的采样数据进行分类，将未分类正确地数据，加入到剩余的多数类数据中，进行下一次采样。
*	One-sided selection (OSS) ：从多数类中选取有代表性的样本，选取的过程依靠数据预处理。

### 2.3 基于数据生成的综合采样

基于数据生成的综合采样(the synthetic minority oversampling technique), 简称 SMOTE，是一种过采样方法。

SMOTE算法基于已有的少数类别的数据，依据数据之间的特征空间上的相似性，来人工生成样本。对于少数类中的一个样本，随机选择其K近邻中的一个样本，随机取一个系数，乘以k近邻的样本，加到原样本上去，形成新样本。


## 3. 模型、算法层面

### 3.1 常规方法

基于树的算法，如C4.5、CART和随机森林不易受到数据不均衡的影响。

### 3.2 代价敏感的方法(Cost-sensitive learning)

代价敏感的方法通过设置不同的代价，描述错分样本的代价。是数据生成方法的一种可行的替代方法。
理论基础：代价敏感的学习方法的基础是代价矩阵的概念。它可以被理解成将某类的样本错分成另一类惩罚。例如：** 在二分类问题中，设置错分少数类样本的代价比多数类要高。** 代价敏感的方法的目标就是最小化分类的代价。方法：

* 代价敏感的数据加权的AdaBoost
* 基于代价敏感的决策树
* 基于代价敏感的神经网络

实际上就是在模型中针对样本的分布，设置权重。


## 4. 评价指标层面

不应该选择单一的指标，如分类准确率来评价模型性能的好坏。

可以设置如精度、召回率、F1、ROC曲线、AUC值等指标，来综合评估。


<br/>
